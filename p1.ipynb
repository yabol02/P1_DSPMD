{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e19ba33",
   "metadata": {},
   "source": [
    "# Diseño de Sistemas de Adquisición y Procesamiento Masivo de Datos\n",
    "\n",
    "## Práctica 1\n",
    "\n",
    "### Yago Boleas y Zakaria Lasry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import plotly.graph_objs as go\n",
    "import polars as pl\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eb6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(\n",
    "    carretera=Path(\"./data/0_carretera.csv\"),\n",
    "    portico=Path(\"./data/1_portico.csv\"),\n",
    "    coche=Path(\"./data/2_coche.csv\"),\n",
    "    coches=Path(\"./data/3_coche_coche.csv\"),\n",
    "    coches_moto=Path(\"./data/4_coche_coche_moto.csv\"),\n",
    "    video=Path(\"./data/5_video_nube_de_puntos\"),\n",
    ")\n",
    "\n",
    "min_, max_ = -30, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lidar_points(\n",
    "    df: pl.DataFrame, iqr_factor: float = 2.0, verbose: bool = True\n",
    ") -> pl.DataFrame:\n",
    "    df_nodup = df.unique(subset=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "    q = df_nodup.select(\n",
    "        [\n",
    "            pl.col(\"x\").quantile(0.25).alias(\"x_q25\"),\n",
    "            pl.col(\"x\").quantile(0.75).alias(\"x_q75\"),\n",
    "            pl.col(\"y\").quantile(0.25).alias(\"y_q25\"),\n",
    "            pl.col(\"y\").quantile(0.75).alias(\"y_q75\"),\n",
    "            pl.col(\"z\").quantile(0.25).alias(\"z_q25\"),\n",
    "            pl.col(\"z\").quantile(0.75).alias(\"z_q75\"),\n",
    "        ]\n",
    "    ).to_dicts()[0]\n",
    "\n",
    "    x_iqr = q[\"x_q75\"] - q[\"x_q25\"]\n",
    "    y_iqr = q[\"y_q75\"] - q[\"y_q25\"]\n",
    "    z_iqr = q[\"z_q75\"] - q[\"z_q25\"]\n",
    "\n",
    "    x_min, x_max = q[\"x_q25\"] - iqr_factor * x_iqr, q[\"x_q75\"] + iqr_factor * x_iqr\n",
    "    y_min, y_max = q[\"y_q25\"] - iqr_factor * y_iqr, q[\"y_q75\"] + iqr_factor * y_iqr\n",
    "    z_min, z_max = q[\"z_q25\"] - iqr_factor * z_iqr, q[\"z_q75\"] + iqr_factor * z_iqr\n",
    "\n",
    "    clean_df = df_nodup.filter(\n",
    "        (pl.col(\"x\").is_between(x_min, x_max))\n",
    "        & (pl.col(\"y\").is_between(y_min, y_max))\n",
    "        & (pl.col(\"z\").is_between(z_min, z_max))\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Puntos originales: {df.height}\")\n",
    "        print(f\"Puntos tras eliminar duplicados y outliers: {clean_df.height}\")\n",
    "\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "def plot_scene(\n",
    "    df, color_var, dataset=None, pov=False, colorscale=\"hot\", opacity=0.8, fig=None\n",
    "):\n",
    "    if fig is None:\n",
    "        fig = go.Figure(\n",
    "            layout=go.Layout(\n",
    "                width=800,\n",
    "                height=800,\n",
    "                scene=dict(\n",
    "                    xaxis=dict(title=\"-X\", range=[min_, max_]),\n",
    "                    yaxis=dict(title=\"Z\", range=[min_, max_]),\n",
    "                    zaxis=dict(title=\"-Y\", range=[min_, max_]),\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=-df[\"x\"],\n",
    "            y=df[\"z\"],\n",
    "            z=-df[\"y\"],\n",
    "            mode=\"markers\",\n",
    "            name=color_var,\n",
    "            marker=dict(\n",
    "                size=1,\n",
    "                color=df[color_var],\n",
    "                colorscale=colorscale,\n",
    "                opacity=opacity,\n",
    "                colorbar=dict(title=color_var),\n",
    "            ),\n",
    "            hoverinfo=\"text\",\n",
    "            hovertext=df[color_var],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if pov:\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=[0],\n",
    "                y=[0],\n",
    "                z=[0],\n",
    "                mode=\"markers\",\n",
    "                name=\"Lidar POV\",\n",
    "                marker=dict(size=5, color=\"Red\"),\n",
    "                hoverinfo=\"text\",\n",
    "                hovertext=\"Lidar POV\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if dataset or fig.layout.title.text == \"\":\n",
    "        fig.update_layout(\n",
    "            showlegend=True,\n",
    "            title=dict(\n",
    "                text=f\"Lidar Point Cloud{f': {dataset}' if dataset else ''}\",\n",
    "                x=0.5,\n",
    "                y=0.9,\n",
    "                xanchor=\"center\",\n",
    "                yanchor=\"top\",\n",
    "                font=dict(\n",
    "                    family=\"Arial, monospace\",\n",
    "                    size=32,\n",
    "                    color=\"Black\",\n",
    "                    variant=\"small-caps\",\n",
    "                ),\n",
    "            ),\n",
    "            font=dict(\n",
    "                family=\"Arial, monospace\",\n",
    "                size=12,\n",
    "                color=\"Black\",\n",
    "                variant=\"small-caps\",\n",
    "            ),\n",
    "        )\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8595418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bounding_box_lines(min_x, max_x, min_y, max_y, min_z, max_z):\n",
    "    x_lines, y_lines, z_lines = [], [], []\n",
    "    # The 8 corners of the box\n",
    "    corners = [\n",
    "        (min_x, min_y, min_z),\n",
    "        (min_x, min_y, max_z),\n",
    "        (min_x, max_y, min_z),\n",
    "        (min_x, max_y, max_z),\n",
    "        (max_x, min_y, min_z),\n",
    "        (max_x, min_y, max_z),\n",
    "        (max_x, max_y, min_z),\n",
    "        (max_x, max_y, max_z),\n",
    "    ]\n",
    "    # The 12 lines connecting the corners\n",
    "    edges = [\n",
    "        (0, 1),\n",
    "        (0, 2),\n",
    "        (0, 4),\n",
    "        (1, 3),\n",
    "        (1, 5),\n",
    "        (2, 3),\n",
    "        (2, 6),\n",
    "        (3, 7),\n",
    "        (4, 5),\n",
    "        (4, 6),\n",
    "        (5, 7),\n",
    "        (6, 7),\n",
    "    ]\n",
    "    for start, end in edges:\n",
    "        x_lines.extend([corners[start][0], corners[end][0], None])\n",
    "        y_lines.extend([corners[start][1], corners[end][1], None])\n",
    "        z_lines.extend([corners[start][2], corners[end][2], None])\n",
    "    return x_lines, y_lines, z_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6525bdef",
   "metadata": {},
   "source": [
    "## ANÁLISIS DE LOS DATOS\n",
    "\n",
    "Lo primero es echar un vistazo a las distintas variables que hay en los conjuntos de datos. Usamos el primer conjunto de datos `carretera` para esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(data[\"carretera\"])\n",
    "df = df.unique([\"x\", \"y\", \"z\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd2682",
   "metadata": {},
   "source": [
    "### Descripción de variables\n",
    "\n",
    "- **x**: coordenada cartesiana en el eje horizontal (eje X).\n",
    "- **y**: coordenada cartesiana en el eje horizontal (eje Y).\n",
    "- **z**: coordenada cartesiana en el eje vertical (eje Z).\n",
    "- **intensity**: intensidad de la señal reflejada que regresa al sensor. Indica cuánta luz láser es reflejada por el objeto detectado.\n",
    "- **t**: marca de tiempo (*timestamp*) en la que se tomó la medición.\n",
    "- **reflectivity**: reflectividad del objeto detectado. Mide la capacidad del objeto para reflejar la luz láser.\n",
    "- **ring**: índice del anillo o línea de escaneo al que pertenece el punto.\n",
    "- **ambient**: nivel de luz ambiental presente en el entorno. \n",
    "- **range**: distancia desde el sensor Lidar hasta el objeto detectado, medida en metros.\n",
    "\n",
    "### Primer vistazo a los datos\n",
    "\n",
    "En esta figura podemos ver la carretera sin ningún tipo de obtáculo por en medio. Se ha decidido también representar la variable `range`, que representa la distancia a la que se encuentra cada uno de los puntos al sensor Lidar. Se muestra también el punto (0, 0, 0) para poder apreciar con mayor claridad esta variable.\n",
    "\n",
    "Para representar los datos también se ha realizado un pequeño procesado de los datos, compuesto por dos etapas:\n",
    "\n",
    "1. **Eliminación de duplicados**: se eliminaron los puntos que tenían coordenadas `x`, `y` y `z` idénticas.\n",
    "2. **Filtrado de puntos atípicos**: se aplicó un método estadístico basado en el *Rango Intercuartílico (IQR)* para detectar y eliminar los puntos que estaban demasiado lejos del grupo principal. Específicamente, se eliminaron todos aquellos puntos que se encontraban a una distancia mayor de 2 veces el IQR por debajo del cuartil 25 o por encima del cuartil 75 para cada eje `(x, y, z)`.\n",
    "\n",
    "Además de la limpieza, se ha representado la variable `range`, que indica la distancia de cada punto al sensor LiDAR, utilizando una **escala de colores** ('*hot*'). Para facilitar la comprensión espacial, se ha añadido un punto de referencia en el origen `(0, 0, 0)`. Es importante notar que, para la visualización, se han ajustado los ejes para una mejor perspectiva: el *eje Z* del gráfico representa la coordenada `y` del sensor (invertida) y el *eje Y* del gráfico la coordenada `z`.  Finalmente, los rangos de los ejes se han limitado a `[-30, 30]` para centrar la vista en el área de interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50374924",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"carretera\"\n",
    "color_var = \"range\"\n",
    "df = pl.read_csv(data[dataset])\n",
    "df = clean_lidar_points(df, verbose=False)\n",
    "fig = plot_scene(df, color_var, dataset, pov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c5955",
   "metadata": {},
   "source": [
    "### Algoritmo de eliminación de puntos estáticos\n",
    "\n",
    "En esta nueva escena se emplean de nuevo los datos de la carretera vacía. El objetivo de esta parte es obtener una representación de las zonas estáticas dentro de la visión del Lidar. Para ello, se implementa un método de **voxelización** para crear un modelo estático del entorno. Cuando llegue una nueva escena, se comprobará que los datos pertenezcan o no a una de las distintas regiones. En caso de pertenecer a esta zona no se tendrán en cuenta a la hora de hacer la clusterización. El proceso para obtener esa escena estática es el siguiente:\n",
    "\n",
    "1.  **Voxelización del espacio**: se define una región de interés en el espacio tridimensional (un cubo de $60 \\times 60 \\times 60$ metros, de -30 a 30 en cada eje) y se divide en una rejilla de $120 \\times 120 \\times 120$ voxels (un voxel es el equivalente tridimensional de un píxel).\n",
    "2.  **Asignación de puntos a voxels**: cada punto de la nube de puntos se asigna a un voxel específico. Esto se logra calculando las coordenadas del voxel (`vx`, `vy`, `vz`) para cada punto basándose en sus coordenadas `x`, `y` y `z` y el tamaño del voxel.\n",
    "3.  **Conteo de puntos por voxel**: se cuenta el número de puntos de la nube que caen dentro de cada voxel. Este conteo se almacena en el array tridimensional `voxel`. Un voxel con un conteo mayor a cero indica que esa región del espacio está \"ocupada\" por un objeto estático.\n",
    "\n",
    "Para dar una idea del resultado de la voxelización se muestra una figura tridimensional con todos los voxels hallados, donde:\n",
    "\n",
    "-   El **tamaño** de los marcadores (cada uno de los puntos) en el gráfico está escalado en función del tamaño del voxel, lo que da una idea de la granularidad de la rejilla.\n",
    "-   El **color** de cada marcador representa el **conteo de puntos** en ese voxel. Esto permite identificar áreas con mayor densidad de puntos, como las superficies de la carretera o la estructura del pórtico.\n",
    "-   Para una visualización más intuitiva, los ejes del gráfico se han intercambiado (`x` $\\Rightarrow$ `-vx`, `y` $\\Rightarrow$ `vz`, `z` $\\Rightarrow$ `-vy`) para que el pórtico se muestre en una orientación más convencional.\n",
    "\n",
    "Este modelo de voxels sirve como una \"huella\" de la escena estática. En el futuro, cuando llegue una nueva nube de puntos, cualquier punto que no caiga en un voxel previamente ocupado se considera parte de un **objeto móvil**, lo que facilita su detección y aislamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c0eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_voxel_grid(\n",
    "    df: pl.DataFrame,\n",
    "    n_regions: int = 120,\n",
    "    min_value: float = min_,\n",
    "    max_value: float = max_,\n",
    ") -> pl.DataFrame:\n",
    "    voxel_size_x = (max_value - min_value) / n_regions\n",
    "    voxel_size_y = (max_value - min_value) / n_regions\n",
    "    voxel_size_z = (max_value - min_value) / n_regions\n",
    "\n",
    "    static_pts = df.with_columns(\n",
    "        (((pl.col(\"x\") - min_value) / voxel_size_x).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vx\"),\n",
    "        (((pl.col(\"y\") - min_value) / voxel_size_y).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vy\"),\n",
    "        (((pl.col(\"z\") - min_value) / voxel_size_z).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vz\"),\n",
    "    )\n",
    "    count = static_pts.group_by([\"vx\", \"vy\", \"vz\"]).len().rename({\"len\": \"count\"})\n",
    "    # voxel = np.zeros((n_regions, n_regions, n_regions), dtype=np.uint16)\n",
    "    # voxel[count[\"vx\"], count[\"vy\"], count[\"vz\"]] = count[\"count\"]\n",
    "    return count\n",
    "\n",
    "\n",
    "def mark_static_points(\n",
    "    df_scene: pl.DataFrame,\n",
    "    static_voxels: pl.DataFrame,\n",
    "    n_regions: int,\n",
    "    min_value: float = min_,\n",
    "    max_value: float = max_,\n",
    ") -> pl.DataFrame:\n",
    "    voxel_size_x = (max_value - min_value) / n_regions\n",
    "    voxel_size_y = (max_value - min_value) / n_regions\n",
    "    voxel_size_z = (max_value - min_value) / n_regions\n",
    "\n",
    "    df_scene = df_scene.with_columns(\n",
    "        (((pl.col(\"x\") - min_value) / voxel_size_x).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vx\"),\n",
    "        (((pl.col(\"y\") - min_value) / voxel_size_y).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vy\"),\n",
    "        (((pl.col(\"z\") - min_value) / voxel_size_z).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vz\"),\n",
    "    )\n",
    "\n",
    "    static_flag = static_voxels.with_columns(pl.lit(-2).alias(\"cluster\"))\n",
    "\n",
    "    df_scene = df_scene.join(\n",
    "        static_flag.select([\"vx\", \"vy\", \"vz\", \"cluster\"]),\n",
    "        on=[\"vx\", \"vy\", \"vz\"],\n",
    "        how=\"left\",\n",
    "    ).fill_null(pl.lit(-1))\n",
    "\n",
    "    return df_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_pts = pl.read_csv(data[\"carretera\"])\n",
    "static_pts = static_pts.unique(subset=[\"x\", \"y\", \"z\"])\n",
    "regions = 240\n",
    "voxels = make_voxel_grid(static_pts, n_regions=regions)\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=-voxels[\"vx\"],\n",
    "            y=voxels[\"vz\"],\n",
    "            z=-voxels[\"vy\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=5 * ((max_ - min_) / regions),\n",
    "                color=voxels[\"count\"],\n",
    "                colorbar=dict(\n",
    "                    title=\"count\",\n",
    "                    tickfont=dict(size=12),\n",
    "                    title_font=dict(size=14),\n",
    "                ),\n",
    "                opacity=0.8,\n",
    "            ),\n",
    "            hoverinfo=\"text\",\n",
    "            hovertext=voxels[\"count\"],\n",
    "        )\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        width=800,\n",
    "        height=800,\n",
    "        scene=dict(\n",
    "            xaxis=dict(range=[-regions, 0]),\n",
    "            yaxis=dict(range=[0, regions]),\n",
    "            zaxis=dict(range=[-regions, 0]),\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1d442",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d73cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_with_dbscan(\n",
    "    df: pl.DataFrame,\n",
    "    feature_cols: list[str],\n",
    "    eps: float = 0.5,\n",
    "    min_samples: int = 10,\n",
    ") -> pl.DataFrame:\n",
    "    df = df.with_row_index(name=\"id\")\n",
    "    subset = df.filter(pl.col(\"cluster\") != -2)\n",
    "    labels = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(\n",
    "        subset.select(feature_cols).to_numpy()\n",
    "    )\n",
    "    subset = subset.with_columns(pl.Series(\"cluster\", labels))\n",
    "    df = (\n",
    "        df.join(subset.select([\"id\", \"cluster\"]), on=\"id\", how=\"left\")\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(\"cluster_right\").is_not_null())\n",
    "            .then(pl.col(\"cluster_right\"))\n",
    "            .otherwise(pl.col(\"cluster\"))\n",
    "            .alias(\"cluster\")\n",
    "        )\n",
    "        .drop(\"cluster_right\")\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c518ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_var = \"cluster\"\n",
    "dataset = \"portico\"\n",
    "\n",
    "df2 = pl.read_csv(data[dataset])\n",
    "df2 = clean_lidar_points(df2, verbose=False)\n",
    "df2 = mark_static_points(df2, voxels, n_regions=regions)\n",
    "df2 = clusters_with_dbscan(\n",
    "    df2,\n",
    "    [\"x\", \"y\", \"z\"],\n",
    ")\n",
    "print(df2[\"cluster\"])\n",
    "\n",
    "fig = plot_scene(df2, color_var, dataset, pov=False, opacity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9e21c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_var = \"cluster\"\n",
    "dataset = \"coche\"\n",
    "\n",
    "df3 = pl.read_csv(data[dataset])\n",
    "df3 = clean_lidar_points(df3, verbose=False)\n",
    "df3 = mark_static_points(df3, voxels, n_regions=regions)\n",
    "df3 = clusters_with_dbscan(\n",
    "    df3,\n",
    "    [\"x\", \"y\", \"z\"],\n",
    ")\n",
    "fig = plot_scene(df3, color_var, dataset, pov=True, opacity=1)\n",
    "for xmin, xmax, ymin, ymax, zmin, zmax in cluster_bounding_cubes(df3):\n",
    "    fig = add_cube(fig, xmin, xmax, ymin, ymax, zmin, zmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f0d8c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_var = \"cluster\"\n",
    "dataset = \"coches\"\n",
    "\n",
    "df4 = pl.read_csv(data[dataset])\n",
    "df4 = clean_lidar_points(df4, verbose=False)\n",
    "df4 = mark_static_points(df4, voxels, n_regions=regions)\n",
    "df4 = clusters_with_dbscan(\n",
    "    df4,\n",
    "    [\"x\", \"y\", \"z\"],\n",
    ")\n",
    "plot_scene(df4, color_var, dataset, pov=True, opacity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4be259",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee712a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_var = \"cluster\"\n",
    "dataset = \"coches_moto\"\n",
    "\n",
    "df5 = pl.read_csv(data[dataset])\n",
    "df5 = clean_lidar_points(df5, verbose=False)\n",
    "df5 = mark_static_points(df5, voxels, n_regions=regions)\n",
    "df5 = clusters_with_dbscan(\n",
    "    df5,\n",
    "    [\"x\", \"y\", \"z\"],\n",
    ")\n",
    "plot_scene(df5.filter(pl.col(\"cluster\") >= -1), color_var, dataset, pov=True, opacity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db68bf1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_dfs = [\n",
    "    pl.scan_csv(os.path.join(data[\"video\"], file)).with_columns(\n",
    "        pl.lit(i).alias(\"frame\")\n",
    "    )\n",
    "    for i, file in enumerate(sorted(os.listdir(data[\"video\"])))\n",
    "]\n",
    "df_raw = pl.concat(lazy_dfs).collect()\n",
    "\n",
    "frames = df_raw[\"frame\"].unique().sort().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edabebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def compute_special_centroids(points: np.ndarray, labels: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Calcula el 'centroide especial' de cada cluster, definido como\n",
    "    el centro geométrico de la bounding box de sus puntos.\n",
    "    Devuelve un dict {cluster_id: (cx, cy)}.\n",
    "    \"\"\"\n",
    "    centroids = {}\n",
    "    for cluster_id in np.unique(labels):\n",
    "        if cluster_id == -1:\n",
    "            continue  # Ignorar ruido\n",
    "        cluster_points = points[labels == cluster_id]\n",
    "        min_x, min_y = cluster_points[:, 0].min(), cluster_points[:, 1].min()\n",
    "        max_x, max_y = cluster_points[:, 0].max(), cluster_points[:, 1].max()\n",
    "        cx, cy = (min_x + max_x) / 2, (min_y + max_y) / 2\n",
    "        centroids[cluster_id] = np.array([cx, cy])\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def match_clusters(\n",
    "    prev_centroids: dict, new_centroids: dict, threshold: float = 1.0\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Asigna los nuevos centroides a los antiguos en función de la distancia mínima.\n",
    "    Devuelve un dict {new_cluster_id: matched_prev_id} (o None si no hay match cercano).\n",
    "    \"\"\"\n",
    "    matches = {}\n",
    "    if not prev_centroids or not new_centroids:\n",
    "        return matches\n",
    "\n",
    "    prev_ids = list(prev_centroids.keys())\n",
    "    new_ids = list(new_centroids.keys())\n",
    "    prev_points = np.array([prev_centroids[i] for i in prev_ids])\n",
    "    new_points = np.array([new_centroids[i] for i in new_ids])\n",
    "\n",
    "    dist_matrix = cdist(new_points, prev_points)\n",
    "    for i, new_id in enumerate(new_ids):\n",
    "        min_idx = np.argmin(dist_matrix[i])\n",
    "        if dist_matrix[i, min_idx] <= threshold:\n",
    "            matches[new_id] = prev_ids[min_idx]\n",
    "        else:\n",
    "            matches[new_id] = None\n",
    "    return matches\n",
    "\n",
    "\n",
    "def compute_velocities(\n",
    "    prev_centroids: dict, new_centroids: dict, matches: dict, dt: float = 1.0\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calcula las velocidades (vx, vy) entre centroides emparejados.\n",
    "    Devuelve {cluster_id: (vx, vy)}.\n",
    "    \"\"\"\n",
    "    velocities = {}\n",
    "    for new_id, prev_id in matches.items():\n",
    "        if prev_id is None:\n",
    "            continue\n",
    "        prev_pos = prev_centroids[prev_id]\n",
    "        new_pos = new_centroids[new_id]\n",
    "        vx, vy = (new_pos - prev_pos) / dt\n",
    "        velocities[new_id] = np.array([vx, vy])\n",
    "    return velocities\n",
    "\n",
    "\n",
    "def predict_positions(\n",
    "    current_centroids: dict, velocities: dict, dt: float = 1.0\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Predice la posición esperada de cada cluster usando su velocidad.\n",
    "    Devuelve {cluster_id: (pred_x, pred_y)}.\n",
    "    \"\"\"\n",
    "    preds = {}\n",
    "    for cid, pos in current_centroids.items():\n",
    "        if cid in velocities:\n",
    "            preds[cid] = pos + velocities[cid] * dt\n",
    "        else:\n",
    "            preds[cid] = pos\n",
    "    return preds\n",
    "\n",
    "\n",
    "def update_tracking_state(\n",
    "    state_df: pl.DataFrame,\n",
    "    frame_id: int,\n",
    "    centroids: dict,\n",
    "    velocities: dict,\n",
    "    preds: dict,\n",
    "):\n",
    "    \"\"\"\n",
    "    Actualiza un DataFrame de estado de tracking con las posiciones, velocidades y predicciones.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for cid in centroids:\n",
    "        cx, cy = centroids[cid]\n",
    "        vx, vy = velocities.get(cid, (np.nan, np.nan))\n",
    "        px, py = preds.get(cid, (np.nan, np.nan))\n",
    "        rows.append((frame_id, cid, cx, cy, vx, vy, px, py))\n",
    "    new_df = pl.DataFrame(\n",
    "        rows,\n",
    "        schema=[\"frame\", \"cluster\", \"cx\", \"cy\", \"vx\", \"vy\", \"px\", \"py\"],\n",
    "        orient=\"row\",\n",
    "    )\n",
    "\n",
    "    return pl.concat([state_df, new_df])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# =============== PIPELINE PRINCIPAL =========================\n",
    "# ============================================================\n",
    "\n",
    "dbscan = DBSCAN(eps=2, min_samples=20)\n",
    "processed_dfs = []\n",
    "tracking_state = pl.DataFrame(\n",
    "    {\n",
    "        \"frame\": pl.Series([], dtype=pl.Int64),\n",
    "        \"cluster\": pl.Series([], dtype=pl.Int64),\n",
    "        \"cx\": pl.Series([], dtype=pl.Float64),\n",
    "        \"cy\": pl.Series([], dtype=pl.Float64),\n",
    "        \"vx\": pl.Series([], dtype=pl.Float64),\n",
    "        \"vy\": pl.Series([], dtype=pl.Float64),\n",
    "        \"px\": pl.Series([], dtype=pl.Float64),\n",
    "        \"py\": pl.Series([], dtype=pl.Float64),\n",
    "    }\n",
    ")\n",
    "\n",
    "frames_to_use = frames[:10]\n",
    "\n",
    "# --- FRAME 0 ---\n",
    "frame0 = df_raw.filter(pl.col(\"frame\") == frames_to_use[0])\n",
    "points0 = frame0.select([\"x\", \"y\", \"z\"]).to_numpy()\n",
    "labels0 = dbscan.fit_predict(points0)\n",
    "centroids0 = compute_special_centroids(points0, labels0)\n",
    "processed_dfs.append(frame0.with_columns(pl.Series(\"cluster\", labels0)))\n",
    "\n",
    "# --- FRAME 1 ---\n",
    "frame1 = df_raw.filter(pl.col(\"frame\") == frames_to_use[1])\n",
    "points1 = frame1.select([\"x\", \"y\", \"z\"]).to_numpy()\n",
    "labels1 = dbscan.fit_predict(points1)\n",
    "centroids1 = compute_special_centroids(points1, labels1)\n",
    "matches01 = match_clusters(centroids0, centroids1)\n",
    "velocities1 = compute_velocities(centroids0, centroids1, matches01)\n",
    "preds1 = predict_positions(centroids1, velocities1)\n",
    "\n",
    "tracking_state = update_tracking_state(\n",
    "    tracking_state, frames_to_use[1], centroids1, velocities1, preds1\n",
    ")\n",
    "processed_dfs.append(frame1.with_columns(pl.Series(\"cluster\", labels1)))\n",
    "\n",
    "# --- RESTO DE FRAMES ---\n",
    "prev_centroids = centroids1\n",
    "prev_velocities = velocities1\n",
    "prev_preds = preds1\n",
    "\n",
    "for frame_id in tqdm(frames_to_use[2:], desc=\"Tracking vehicles\"):\n",
    "    frame_df = df_raw.filter(pl.col(\"frame\") == frame_id)\n",
    "    points = frame_df.select([\"x\", \"y\", \"z\"]).to_numpy()\n",
    "\n",
    "    labels = dbscan.fit_predict(points)\n",
    "    centroids = compute_special_centroids(points, labels)\n",
    "\n",
    "    matches = match_clusters(prev_preds, centroids, threshold=1.0)\n",
    "    velocities = compute_velocities(prev_centroids, centroids, matches)\n",
    "    preds = predict_positions(centroids, velocities)\n",
    "\n",
    "    tracking_state = update_tracking_state(\n",
    "        tracking_state, frame_id, centroids, velocities, preds\n",
    "    )\n",
    "    processed_dfs.append(frame_df.with_columns(pl.Series(\"cluster\", labels)))\n",
    "\n",
    "    prev_centroids = centroids\n",
    "    prev_velocities = velocities\n",
    "    prev_preds = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59424b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_lidar_clusters_3d_interactive(df: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    Muestra un scatter 3D interactivo de los puntos LiDAR coloreados por cluster,\n",
    "    con un slider para moverse entre frames.\n",
    "\n",
    "    Parámetros:\n",
    "        df: polars.DataFrame\n",
    "            DataFrame concatenado con columnas ['x','y','z','cluster','frame'].\n",
    "    \"\"\"\n",
    "    # Aseguramos que las columnas necesarias existen\n",
    "    required_cols = {\"x\", \"y\", \"z\", \"cluster\", \"frame\"}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        raise ValueError(f\"El DataFrame debe contener las columnas {required_cols}\")\n",
    "\n",
    "\n",
    "    # Scatter 3D animado con slider\n",
    "    fig = px.scatter_3d(\n",
    "        df,\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        z=\"z\",\n",
    "        color=\"cluster\",\n",
    "        animation_frame=\"frame\",\n",
    "        title=\"Evolución temporal de los clusters LiDAR\",\n",
    "        width=900,\n",
    "        height=700,\n",
    "        color_continuous_scale=\"Viridis\"  # escala de color agradable\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker=dict(size=3, opacity=0.8))\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\",\n",
    "            yaxis_title=\"Y\",\n",
    "            zaxis_title=\"Z\",\n",
    "            aspectmode=\"data\"  # mantiene proporciones reales\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=40),\n",
    "        coloraxis_colorbar=dict(title=\"Cluster\"),\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plot_lidar_clusters_3d_interactive(pl.concat(processed_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dfs = []\n",
    "\n",
    "dbscan = DBSCAN(eps=2, min_samples=20)\n",
    "\n",
    "print(\"Clustering points for each frame...\")\n",
    "for frame_id in frames:\n",
    "    frame_df = df_raw.filter(pl.col(\"frame\") == frame_id)\n",
    "    points = frame_df.select([\"x\", \"y\", \"z\"]).to_numpy()\n",
    "\n",
    "    if len(points) > 0:\n",
    "        clusters = dbscan.fit_predict(points)\n",
    "        processed_df = frame_df.with_columns(pl.Series(\"cluster\", clusters))\n",
    "        processed_dfs.append(processed_df)\n",
    "\n",
    "df_clustered = pl.concat(processed_dfs)\n",
    "\n",
    "print(\"Clustering complete.\")\n",
    "\n",
    "all_values = pl.concat([df_clustered[\"x\"], df_clustered[\"y\"], df_clustered[\"z\"]])\n",
    "min_global = all_values.min()\n",
    "max_global = all_values.max()\n",
    "\n",
    "animation_frames = []\n",
    "for f in frames:\n",
    "    current_frame_data = df_clustered.filter(pl.col(\"frame\") == f)\n",
    "\n",
    "    non_noise_points = current_frame_data.filter(pl.col(\"cluster\") >= 0)\n",
    "\n",
    "    cluster_labels = non_noise_points[\"cluster\"].unique().to_list()\n",
    "\n",
    "    box_x, box_y, box_z = [], [], []\n",
    "    for cluster_id in cluster_labels:\n",
    "        cluster_points = current_frame_data.filter(pl.col(\"cluster\") == cluster_id)\n",
    "\n",
    "        min_vals = cluster_points.select([\"x\", \"y\", \"z\"]).min().row(0)\n",
    "        max_vals = cluster_points.select([\"x\", \"y\", \"z\"]).max().row(0)\n",
    "\n",
    "        x_lines, y_lines, z_lines = create_bounding_box_lines(\n",
    "            min_vals[0], max_vals[0], min_vals[1], max_vals[1], min_vals[2], max_vals[2]\n",
    "        )\n",
    "        box_x.extend(x_lines)\n",
    "        box_y.extend(y_lines)\n",
    "        box_z.extend(z_lines)\n",
    "\n",
    "    current_frame_data = df_clustered.filter(pl.col(\"frame\") == f)\n",
    "\n",
    "    cluster_labels = current_frame_data[\"cluster\"]\n",
    "    cluster_labels = cluster_labels.filter(cluster_labels >= 0).unique().to_list()\n",
    "\n",
    "    box_x, box_y, box_z = [], [], []\n",
    "    for cluster_id in cluster_labels:\n",
    "        cluster_points = current_frame_data.filter(pl.col(\"cluster\") == cluster_id)\n",
    "\n",
    "        min_vals = cluster_points.select([\"x\", \"y\", \"z\"]).min().row(0)\n",
    "        max_vals = cluster_points.select([\"x\", \"y\", \"z\"]).max().row(0)\n",
    "\n",
    "        x_lines, y_lines, z_lines = create_bounding_box_lines(\n",
    "            min_vals[0], max_vals[0], min_vals[1], max_vals[1], min_vals[2], max_vals[2]\n",
    "        )\n",
    "        box_x.extend(x_lines)\n",
    "        box_y.extend(y_lines)\n",
    "        box_z.extend(z_lines)\n",
    "\n",
    "    animation_frames.append(\n",
    "        go.Frame(\n",
    "            data=[\n",
    "                go.Scatter3d(\n",
    "                    x=current_frame_data[\"x\"],\n",
    "                    y=current_frame_data[\"y\"],\n",
    "                    z=current_frame_data[\"z\"],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=1, color=\"red\", opacity=0.8),\n",
    "                ),\n",
    "                go.Scatter3d(\n",
    "                    x=box_x,\n",
    "                    y=box_y,\n",
    "                    z=box_z,\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(color=\"black\", width=2),\n",
    "                ),\n",
    "            ],\n",
    "            name=str(f),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "df0 = animation_frames[0].data\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=df0,\n",
    "    layout=go.Layout(\n",
    "        width=800,\n",
    "        height=800,\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=\"X\", range=[min_global, max_global]),\n",
    "            yaxis=dict(title=\"Y\", range=[min_global, max_global]),\n",
    "            zaxis=dict(title=\"Z\", range=[min_global, max_global]),\n",
    "            aspectmode=\"cube\",\n",
    "        ),\n",
    "    ),\n",
    "    frames=animation_frames,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Lidar Point Cloud: video\",\n",
    "        x=0.5,\n",
    "        y=0.9,\n",
    "        xanchor=\"center\",\n",
    "        yanchor=\"top\",\n",
    "        font=dict(\n",
    "            family=\"Arial, monospace\", size=32, color=\"Black\", variant=\"small-caps\"\n",
    "        ),\n",
    "    ),\n",
    "    font=dict(\n",
    "        family=\"Arial, monospace\",\n",
    "        size=12,\n",
    "        color=\"Black\",\n",
    "        variant=\"small-caps\",\n",
    "    ),\n",
    "    sliders=[\n",
    "        dict(\n",
    "            steps=[\n",
    "                dict(\n",
    "                    args=[\n",
    "                        [str(f)],\n",
    "                        dict(\n",
    "                            frame={\"duration\": 200, \"redraw\": True},\n",
    "                            mode=\"immediate\",\n",
    "                        ),\n",
    "                    ],\n",
    "                    label=str(f),\n",
    "                    method=\"animate\",\n",
    "                )\n",
    "                for f in frames\n",
    "            ],\n",
    "            transition={\"duration\": 0},\n",
    "            x=0.1,\n",
    "            y=0,\n",
    "            len=0.9,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e4f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_raw.filter(pl.col(\"frame\") == 200)\n",
    "labels = DBSCAN(eps=2, min_samples=20).fit_predict(temp.select([\"x\", \"z\"]))\n",
    "temp = temp.with_columns(pl.Series(\"cluster\", labels))\n",
    "\n",
    "centroids = (\n",
    "    temp.filter(pl.col(\"cluster\") != -1)\n",
    "    .group_by(\"cluster\")\n",
    "    .agg(\n",
    "        [\n",
    "            pl.col(\"x\").mean(),\n",
    "            pl.col(\"y\").mean(),\n",
    "            pl.col(\"z\").mean(),\n",
    "        ]\n",
    "    )\n",
    "    .sort(\"cluster\")\n",
    "    .with_columns(pl.lit(True).alias(\"active\"))\n",
    ")\n",
    "\n",
    "centroids\n",
    "temp2 = df_raw.filter(pl.col(\"frame\") == 201)\n",
    "labels = DBSCAN(eps=2, min_samples=20).fit_predict(temp2.select([\"x\", \"z\"]))\n",
    "temp2 = temp2.with_columns(pl.Series(\"cluster\", labels))\n",
    "centroids2 = (\n",
    "    temp2.filter(pl.col(\"cluster\") != -1)\n",
    "    .group_by(\"cluster\")\n",
    "    .agg(\n",
    "        [\n",
    "            pl.col(\"x\").mean(),\n",
    "            pl.col(\"y\").mean(),\n",
    "            pl.col(\"z\").mean(),\n",
    "        ]\n",
    "    )\n",
    "    .sort(\"cluster\")\n",
    "    .with_columns(pl.lit(True).alias(\"active\"))\n",
    ")\n",
    "\n",
    "print(centroids, centroids2)\n",
    "\n",
    "# c1 = centroids.select(['x', 'y', 'z']).to_numpy()\n",
    "# c2 = centroids2.select(['x', 'y', 'z']).to_numpy()\n",
    "# np.linalg.norm(c2-c1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f395c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = centroids.select([\"x\", \"y\", \"z\"]).to_numpy()\n",
    "c2 = centroids2[0].select([\"x\", \"y\", \"z\"]).to_numpy()\n",
    "(np.linalg.norm(c2 - c1, axis=1))\n",
    "centroids[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d5ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(df: pl.DataFrame):\n",
    "    return (\n",
    "        df.filter(pl.col(\"cluster\") != -1)\n",
    "        .group_by(\"cluster\")\n",
    "        .agg([pl.col(\"x\").mean(), pl.col(\"y\").mean(), pl.col(\"z\").mean()])\n",
    "        .sort(\"cluster\")\n",
    "        .with_columns(pl.lit(True).alias(\"active\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7add19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = pl.DataFrame({\"x\": [], \"y\": [], \"z\": [], \"active\": []})\n",
    "centroids.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d6cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 1.0\n",
    "all_centroids = pl.DataFrame({\"x\": [], \"y\": [], \"z\": [], \"active\": [], \"frame\": []})\n",
    "for frame in tqdm(df_raw[\"frame\"].unique().to_list()):\n",
    "    temp = df_raw.filter(pl.col(\"frame\") == frame)\n",
    "    labels = DBSCAN(eps=2, min_samples=20).fit_predict(temp.select([\"x\", \"y\", \"z\"]))\n",
    "    temp = temp.with_columns(pl.Series(\"cluster\", labels))\n",
    "    new_centroids = get_centroids(temp)\n",
    "    new_centroids = new_centroids.with_columns(pl.lit(frame).alias(\"frame\"))\n",
    "    if all_centroids.height == 0:\n",
    "        all_centroids = new_centroids\n",
    "    else:\n",
    "        for cent in new_centroids.select([\"x\", \"y\", \"z\"]).iter_rows():\n",
    "            centroids = all_centroids.select([\"x\", \"y\", \"z\"]).to_numpy()\n",
    "            cent = np.array(cent)\n",
    "            dist = np.linalg.norm(centroids - cent, axis=1)\n",
    "            idx = int(np.argmin(dist))\n",
    "            if dist[0] <= THRESHOLD:\n",
    "                # print(all_centroids[idx, :4])\n",
    "                all_centroids[idx, \"x\"] = cent[0]\n",
    "                all_centroids[idx, \"y\"] = cent[1]\n",
    "                all_centroids[idx, \"z\"] = cent[2]\n",
    "            else:\n",
    "                all_centroids = pl.concat(\n",
    "                    [\n",
    "                        all_centroids,\n",
    "                        pl.DataFrame(\n",
    "                            {\n",
    "                                \"cluster\": [all_centroids.height],\n",
    "                                \"x\": [cent[0]],\n",
    "                                \"y\": [cent[1]],\n",
    "                                \"z\": [cent[2]],\n",
    "                                \"active\": [True],\n",
    "                            }\n",
    "                        ),\n",
    "                    ]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76af794",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_centroids.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd842457",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.array([-17.35, 1.84, 1.18]) - np.array([-17.51, 1.85, 1.17]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_raw.filter(pl.col(\"frame\") == 123)\n",
    "temp = clusters_with_dbscan(temp, [\"x\", \"y\", \"z\"], eps=2, min_samples=20)\n",
    "\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=temp[\"x\"],\n",
    "            y=temp[\"y\"],\n",
    "            z=temp[\"z\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=1, color=temp[\"cluster\"], colorscale=\"hot\", opacity=0.8),\n",
    "        )\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        width=800,\n",
    "        height=800,\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=\"X\", range=[min_global, max_global]),\n",
    "            yaxis=dict(title=\"Y\", range=[min_global, max_global]),\n",
    "            zaxis=dict(title=\"Z\", range=[min_global, max_global]),\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6ffcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
