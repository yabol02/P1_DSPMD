{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e19ba33",
   "metadata": {},
   "source": [
    "# Diseño de Sistemas de Adquisición y Procesamiento Masivo de Datos\n",
    "\n",
    "## Práctica 1\n",
    "\n",
    "### Yago Boleas y Zakaria Lasry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eb6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(\n",
    "    carretera=Path(\"./data/0_carretera.csv\"),\n",
    "    portico=Path(\"./data/1_portico.csv\"),\n",
    "    coche=Path(\"./data/2_coche.csv\"),\n",
    "    coches=Path(\"./data/3_coche_coche.csv\"),\n",
    "    coches_moto=Path(\"./data/4_coche_coche_moto.csv\"),\n",
    "    video=Path(\"./data/5_video_nube_de_puntos\"),\n",
    ")\n",
    "\n",
    "min_, max_ = -30, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lidar_points(\n",
    "    df: pl.DataFrame, iqr_factor: float = 2.0, verbose: bool = True\n",
    ") -> pl.DataFrame:\n",
    "    df_nodup = df.unique(subset=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "    q = df_nodup.select(\n",
    "        [\n",
    "            pl.col(\"x\").quantile(0.25).alias(\"x_q25\"),\n",
    "            pl.col(\"x\").quantile(0.75).alias(\"x_q75\"),\n",
    "            pl.col(\"y\").quantile(0.25).alias(\"y_q25\"),\n",
    "            pl.col(\"y\").quantile(0.75).alias(\"y_q75\"),\n",
    "            pl.col(\"z\").quantile(0.25).alias(\"z_q25\"),\n",
    "            pl.col(\"z\").quantile(0.75).alias(\"z_q75\"),\n",
    "        ]\n",
    "    ).to_dicts()[0]\n",
    "\n",
    "    x_iqr = q[\"x_q75\"] - q[\"x_q25\"]\n",
    "    y_iqr = q[\"y_q75\"] - q[\"y_q25\"]\n",
    "    z_iqr = q[\"z_q75\"] - q[\"z_q25\"]\n",
    "\n",
    "    x_min, x_max = q[\"x_q25\"] - iqr_factor * x_iqr, q[\"x_q75\"] + iqr_factor * x_iqr\n",
    "    y_min, y_max = q[\"y_q25\"] - iqr_factor * y_iqr, q[\"y_q75\"] + iqr_factor * y_iqr\n",
    "    z_min, z_max = q[\"z_q25\"] - iqr_factor * z_iqr, q[\"z_q75\"] + iqr_factor * z_iqr\n",
    "\n",
    "    clean_df = df_nodup.filter(\n",
    "        (pl.col(\"x\").is_between(x_min, x_max))\n",
    "        & (pl.col(\"y\").is_between(y_min, y_max))\n",
    "        & (pl.col(\"z\").is_between(z_min, z_max))\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Puntos originales: {df.height}\")\n",
    "        print(f\"Puntos tras eliminar duplicados y outliers: {clean_df.height}\")\n",
    "\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "def plot_scene(\n",
    "    df, color_var, dataset=None, pov=False, colorscale=\"hot\", opacity=0.8, fig=None\n",
    "):\n",
    "    if fig is None:\n",
    "        fig = go.Figure(\n",
    "            layout=go.Layout(\n",
    "                width=800,\n",
    "                height=800,\n",
    "                scene=dict(\n",
    "                    xaxis=dict(title=\"-X\", range=[min_, max_]),\n",
    "                    yaxis=dict(title=\"Z\", range=[min_, max_]),\n",
    "                    zaxis=dict(title=\"-Y\", range=[min_, max_]),\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=-df[\"x\"],\n",
    "            y=df[\"z\"],\n",
    "            z=-df[\"y\"],\n",
    "            mode=\"markers\",\n",
    "            name=color_var,\n",
    "            marker=dict(\n",
    "                size=1,\n",
    "                color=df[color_var],\n",
    "                colorscale=colorscale,\n",
    "                opacity=opacity,\n",
    "                colorbar=dict(title=color_var),\n",
    "            ),\n",
    "            hoverinfo=\"text\",\n",
    "            hovertext=df[color_var],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if pov:\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=[0],\n",
    "                y=[0],\n",
    "                z=[0],\n",
    "                mode=\"markers\",\n",
    "                name=\"Lidar POV\",\n",
    "                marker=dict(size=5, color=\"Red\"),\n",
    "                hoverinfo=\"text\",\n",
    "                hovertext=\"Lidar POV\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if dataset or fig.layout.title.text == \"\":\n",
    "        fig.update_layout(\n",
    "            showlegend=True,\n",
    "            title=dict(\n",
    "                text=f\"Lidar Point Cloud{f': {dataset}' if dataset else ''}\",\n",
    "                x=0.5,\n",
    "                y=0.9,\n",
    "                xanchor=\"center\",\n",
    "                yanchor=\"top\",\n",
    "                font=dict(\n",
    "                    family=\"Arial, monospace\",\n",
    "                    size=32,\n",
    "                    color=\"Black\",\n",
    "                    variant=\"small-caps\",\n",
    "                ),\n",
    "            ),\n",
    "            font=dict(\n",
    "                family=\"Arial, monospace\",\n",
    "                size=12,\n",
    "                color=\"Black\",\n",
    "                variant=\"small-caps\",\n",
    "            ),\n",
    "        )\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8595418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bounding_box_lines(min_x, max_x, min_y, max_y, min_z, max_z):\n",
    "    x_lines, y_lines, z_lines = [], [], []\n",
    "    # Corners of the box\n",
    "    corners = [\n",
    "        (min_x, min_y, min_z),\n",
    "        (min_x, min_y, max_z),\n",
    "        (min_x, max_y, min_z),\n",
    "        (min_x, max_y, max_z),\n",
    "        (max_x, min_y, min_z),\n",
    "        (max_x, min_y, max_z),\n",
    "        (max_x, max_y, min_z),\n",
    "        (max_x, max_y, max_z),\n",
    "    ]\n",
    "    # Lines of the box\n",
    "    edges = [\n",
    "        (0, 1),\n",
    "        (0, 2),\n",
    "        (0, 4),\n",
    "        (1, 3),\n",
    "        (1, 5),\n",
    "        (2, 3),\n",
    "        (2, 6),\n",
    "        (3, 7),\n",
    "        (4, 5),\n",
    "        (4, 6),\n",
    "        (5, 7),\n",
    "        (6, 7),\n",
    "    ]\n",
    "    for start, end in edges:\n",
    "        x_lines.extend([corners[start][0], corners[end][0], None])\n",
    "        y_lines.extend([corners[start][1], corners[end][1], None])\n",
    "        z_lines.extend([corners[start][2], corners[end][2], None])\n",
    "    return x_lines, y_lines, z_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6525bdef",
   "metadata": {},
   "source": [
    "## ANÁLISIS DE LOS DATOS\n",
    "\n",
    "Lo primero es echar un vistazo a las distintas variables que hay en los conjuntos de datos. Usamos el primer conjunto de datos `carretera` para esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(data[\"carretera\"])\n",
    "df = df.unique([\"x\", \"y\", \"z\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd2682",
   "metadata": {},
   "source": [
    "### Descripción de variables\n",
    "\n",
    "- **x**: coordenada cartesiana en el eje horizontal (eje X).\n",
    "- **y**: coordenada cartesiana en el eje horizontal (eje Y).\n",
    "- **z**: coordenada cartesiana en el eje vertical (eje Z).\n",
    "- **intensity**: intensidad de la señal reflejada que regresa al sensor. Indica cuánta luz láser es reflejada por el objeto detectado.\n",
    "- **t**: marca de tiempo (*timestamp*) en la que se tomó la medición.\n",
    "- **reflectivity**: reflectividad del objeto detectado. Mide la capacidad del objeto para reflejar la luz láser.\n",
    "- **ring**: índice del anillo o línea de escaneo al que pertenece el punto.\n",
    "- **ambient**: nivel de luz ambiental presente en el entorno. \n",
    "- **range**: distancia desde el sensor Lidar hasta el objeto detectado, medida en metros.\n",
    "\n",
    "### Primer vistazo a los datos\n",
    "\n",
    "En esta figura podemos ver la carretera sin ningún tipo de obtáculo por en medio. Se ha decidido también representar la variable `range`, que representa la distancia a la que se encuentra cada uno de los puntos al sensor Lidar. Se muestra también el punto (0, 0, 0) para poder apreciar con mayor claridad esta variable.\n",
    "\n",
    "Para representar los datos también se ha realizado un pequeño procesado de los datos, compuesto por dos etapas:\n",
    "\n",
    "1. **Eliminación de duplicados**: se eliminaron los puntos que tenían coordenadas `x`, `y` y `z` idénticas.\n",
    "2. **Filtrado de puntos atípicos**: se aplicó un método estadístico basado en el *Rango Intercuartílico (IQR)* para detectar y eliminar los puntos que estaban demasiado lejos del grupo principal. Específicamente, se eliminaron todos aquellos puntos que se encontraban a una distancia mayor de 2 veces el IQR por debajo del cuartil 25 o por encima del cuartil 75 para cada eje `(x, y, z)`.\n",
    "\n",
    "Además de la limpieza, se ha representado la variable `range`, que indica la distancia de cada punto al sensor LiDAR, utilizando una **escala de colores** ('*hot*'). Para facilitar la comprensión espacial, se ha añadido un punto de referencia en el origen `(0, 0, 0)`. Es importante notar que, para la visualización, se han ajustado los ejes para una mejor perspectiva: el *eje Z* del gráfico representa la coordenada `y` del sensor (invertida) y el *eje Y* del gráfico la coordenada `z`.  Finalmente, los rangos de los ejes se han limitado a `[-30, 30]` para centrar la vista en el área de interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50374924",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"carretera\"\n",
    "color_var = \"range\"\n",
    "df = pl.read_csv(data[dataset])\n",
    "df = clean_lidar_points(df, verbose=False)\n",
    "fig = plot_scene(df, color_var, dataset, pov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c5955",
   "metadata": {},
   "source": [
    "### Algoritmo de eliminación de puntos estáticos\n",
    "\n",
    "En esta nueva escena se emplean de nuevo los datos de la carretera vacía. El objetivo de esta parte es obtener una representación de las zonas estáticas dentro de la visión del Lidar. Para ello, se implementa un método de **voxelización** para crear un modelo estático del entorno. Cuando llegue una nueva escena, se comprobará que los datos pertenezcan o no a una de las distintas regiones. En caso de pertenecer a esta zona no se tendrán en cuenta a la hora de hacer la clusterización. El proceso para obtener esa escena estática es el siguiente:\n",
    "\n",
    "1.  **Voxelización del espacio**: se define una región de interés en el espacio tridimensional (un cubo de $60 \\times 60 \\times 60$ metros, de -30 a 30 en cada eje) y se divide en una rejilla de $120 \\times 120 \\times 120$ voxels (un voxel es el equivalente tridimensional de un píxel).\n",
    "2.  **Asignación de puntos a voxels**: cada punto de la nube de puntos se asigna a un voxel específico. Esto se logra calculando las coordenadas del voxel (`vx`, `vy`, `vz`) para cada punto basándose en sus coordenadas `x`, `y` y `z` y el tamaño del voxel.\n",
    "3.  **Conteo de puntos por voxel**: se cuenta el número de puntos de la nube que caen dentro de cada voxel. Este conteo se almacena en el array tridimensional `voxel`. Un voxel con un conteo mayor a cero indica que esa región del espacio está \"ocupada\" por un objeto estático.\n",
    "\n",
    "Para dar una idea del resultado de la voxelización se muestra una figura tridimensional con todos los voxels hallados, donde:\n",
    "\n",
    "-   El **tamaño** de los marcadores (cada uno de los puntos) en el gráfico está escalado en función del tamaño del voxel, lo que da una idea de la granularidad de la rejilla.\n",
    "-   El **color** de cada marcador representa el **conteo de puntos** en ese voxel. Esto permite identificar áreas con mayor densidad de puntos, como las superficies de la carretera o la estructura del pórtico.\n",
    "-   Para una visualización más intuitiva, los ejes del gráfico se han intercambiado (`x` $\\Rightarrow$ `-vx`, `y` $\\Rightarrow$ `vz`, `z` $\\Rightarrow$ `-vy`) para que el pórtico se muestre en una orientación más convencional.\n",
    "\n",
    "Este modelo de voxels sirve como una \"huella\" de la escena estática. En el futuro, cuando llegue una nueva nube de puntos, cualquier punto que no caiga en un voxel previamente ocupado se considera parte de un **objeto móvil**, lo que facilita su detección y aislamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c0eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_voxel_grid(\n",
    "    df: pl.DataFrame,\n",
    "    n_regions: int = 120,\n",
    "    min_value: float = min_,\n",
    "    max_value: float = max_,\n",
    ") -> pl.DataFrame:\n",
    "    voxel_size_x = (max_value - min_value) / n_regions\n",
    "    voxel_size_y = (max_value - min_value) / n_regions\n",
    "    voxel_size_z = (max_value - min_value) / n_regions\n",
    "\n",
    "    static_pts = df.with_columns(\n",
    "        (((pl.col(\"x\") - min_value) / voxel_size_x).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vx\"),\n",
    "        (((pl.col(\"y\") - min_value) / voxel_size_y).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vy\"),\n",
    "        (((pl.col(\"z\") - min_value) / voxel_size_z).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vz\"),\n",
    "    )\n",
    "    count = static_pts.group_by([\"vx\", \"vy\", \"vz\"]).len().rename({\"len\": \"count\"})\n",
    "    # voxel = np.zeros((n_regions, n_regions, n_regions), dtype=np.uint16)\n",
    "    # voxel[count[\"vx\"], count[\"vy\"], count[\"vz\"]] = count[\"count\"]\n",
    "    return count\n",
    "\n",
    "\n",
    "def mark_static_points(\n",
    "    df_scene: pl.DataFrame,\n",
    "    static_voxels: pl.DataFrame,\n",
    "    n_regions: int,\n",
    "    min_value: float = min_,\n",
    "    max_value: float = max_,\n",
    ") -> pl.DataFrame:\n",
    "    voxel_size_x = (max_value - min_value) / n_regions\n",
    "    voxel_size_y = (max_value - min_value) / n_regions\n",
    "    voxel_size_z = (max_value - min_value) / n_regions\n",
    "\n",
    "    df_scene = df_scene.with_columns(\n",
    "        (((pl.col(\"x\") - min_value) / voxel_size_x).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vx\"),\n",
    "        (((pl.col(\"y\") - min_value) / voxel_size_y).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vy\"),\n",
    "        (((pl.col(\"z\") - min_value) / voxel_size_z).floor().clip(0, n_regions - 1))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"vz\"),\n",
    "    )\n",
    "\n",
    "    static_flag = static_voxels.with_columns(pl.lit(-2).alias(\"cluster\"))\n",
    "\n",
    "    df_scene = df_scene.join(\n",
    "        static_flag.select([\"vx\", \"vy\", \"vz\", \"cluster\"]),\n",
    "        on=[\"vx\", \"vy\", \"vz\"],\n",
    "        how=\"left\",\n",
    "    ).fill_null(pl.lit(-1))\n",
    "\n",
    "    return df_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_pts = pl.read_csv(data[\"carretera\"])\n",
    "static_pts = static_pts.unique(subset=[\"x\", \"y\", \"z\"])\n",
    "regions = 120\n",
    "voxels = make_voxel_grid(static_pts, n_regions=regions)\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=-voxels[\"vx\"],\n",
    "            y=voxels[\"vz\"],\n",
    "            z=-voxels[\"vy\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=5 * ((max_ - min_) / regions),\n",
    "                color=voxels[\"count\"],\n",
    "                colorbar=dict(\n",
    "                    title=\"count\",\n",
    "                    tickfont=dict(size=12),\n",
    "                    title_font=dict(size=14),\n",
    "                ),\n",
    "                opacity=0.8,\n",
    "            ),\n",
    "            hoverinfo=\"text\",\n",
    "            hovertext=voxels[\"count\"],\n",
    "        )\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        width=800,\n",
    "        height=800,\n",
    "        scene=dict(\n",
    "            xaxis=dict(range=[-regions, 0]),\n",
    "            yaxis=dict(range=[0, regions]),\n",
    "            zaxis=dict(range=[-regions, 0]),\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1d442",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d73cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_with_dbscan(\n",
    "    df: pl.DataFrame,\n",
    "    feature_cols: list[str],\n",
    "    eps: float = 0.7,\n",
    "    min_samples: int = 12,\n",
    ") -> pl.DataFrame:\n",
    "    df = df.with_row_index(name=\"id\")\n",
    "    subset = df.filter(pl.col(\"cluster\") != -2)\n",
    "    labels = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(\n",
    "        subset.select(feature_cols).to_numpy()\n",
    "    )\n",
    "    subset = subset.with_columns(pl.Series(\"cluster\", labels))\n",
    "    df = (\n",
    "        df.join(subset.select([\"id\", \"cluster\"]), on=\"id\", how=\"left\")\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(\"cluster_right\").is_not_null())\n",
    "            .then(pl.col(\"cluster_right\"))\n",
    "            .otherwise(pl.col(\"cluster\"))\n",
    "            .alias(\"cluster\")\n",
    "        )\n",
    "        .drop(\"cluster_right\")\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c518ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_var = \"cluster\"\n",
    "dataset = \"portico\"\n",
    "\n",
    "df2 = pl.read_csv(data[dataset])\n",
    "df2 = clean_lidar_points(df2, verbose=False)\n",
    "df2 = mark_static_points(df2, voxels, n_regions=regions)\n",
    "df2 = clusters_with_dbscan(\n",
    "    df2,\n",
    "    [\"x\", \"y\", \"z\"],\n",
    ")\n",
    "\n",
    "fig = plot_scene(df2, color_var, dataset, pov=False, opacity=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9e21c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_var = \"cluster\"\n",
    "dataset = \"coche\"\n",
    "\n",
    "df3 = pl.read_csv(data[dataset])\n",
    "df3 = clean_lidar_points(df3, verbose=False)\n",
    "df3 = mark_static_points(df3, voxels, n_regions=regions)\n",
    "df3 = clusters_with_dbscan(\n",
    "    df3,\n",
    "    [\"x\", \"y\", \"z\"],\n",
    ")\n",
    "fig = plot_scene(df3, color_var, dataset, pov=True, opacity=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f0d8c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_var = \"cluster\"\n",
    "dataset = \"coches\"\n",
    "\n",
    "df4 = pl.read_csv(data[dataset])\n",
    "df4 = clean_lidar_points(df4, verbose=False)\n",
    "df4 = mark_static_points(df4, voxels, n_regions=regions)\n",
    "df4 = clusters_with_dbscan(\n",
    "    df4,\n",
    "    [\"x\", \"y\", \"z\"],\n",
    ")\n",
    "plot_scene(df4, color_var, dataset, pov=True, opacity=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4be259",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee712a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_var = \"cluster\"\n",
    "dataset = \"coches_moto\"\n",
    "\n",
    "df5 = pl.read_csv(data[dataset])\n",
    "df5 = clean_lidar_points(df5, verbose=False)\n",
    "df5 = mark_static_points(df5, voxels, n_regions=regions)\n",
    "df5 = clusters_with_dbscan(\n",
    "    df5,\n",
    "    [\"x\", \"y\", \"z\"],\n",
    ")\n",
    "plot_scene(df5, color_var, dataset, pov=True, opacity=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a80efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans = df5.filter(pl.col(\"cluster\") >= -1)\n",
    "\n",
    "K = (\n",
    "    df5.filter(pl.col(\"cluster\") >= 0)\n",
    "    .select(pl.col(\"cluster\").unique().len())\n",
    "    .item()\n",
    ")\n",
    "print(f\"Número de clústeres detectados por DBSCAN: {K}\")\n",
    "\n",
    "X = df5.filter(pl.col(\"cluster\") >= -1).select([\"x\", \"y\", \"z\"]).to_numpy()\n",
    "kmeans = KMeans(n_clusters=K, random_state=0).fit(X)\n",
    "\n",
    "df_kmeans = df_kmeans.with_columns(pl.Series(\"kmeans_cluster\", kmeans.labels_))\n",
    "plot_scene(df_kmeans, \"kmeans_cluster\", dataset, pov=True, opacity=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cb4fc",
   "metadata": {},
   "source": [
    "Una vez vistos estos resultados, vemso que en este caso aplicar **KMeans** carece de sentido práctico por varias razones fundamentales. En primer lugar, el algoritmo exige conocer el número de clústeres $K$ antes de ejecutarse, lo cual no es viable para el caso a evaluar. El otro gran problema se puede apreciar al mostrar los datos de forma gráfica. En caso de no limpiar con una precisión impecable los datos, el algoritmo **KMeans** si o si clasificará puntos de ruido en algún clúster, los cuales con DBSCAN son tratados como lo que son. Otro de los fundamentos para evitar este algoritmo es que no hace una separación ideal de los clústeres. En la figura superior se puede ver cómo en uno de los 3 clústeres que salieron del algoritmo hay dos vehículos, cuando el objetivo de aplicar técnicas de *clustering* en este caso es separar ambos elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db68bf1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_dfs = [\n",
    "    pl.scan_csv(os.path.join(data[\"video\"], file)).with_columns(\n",
    "        pl.lit(i).alias(\"frame\")\n",
    "    )\n",
    "    for i, file in enumerate(sorted(os.listdir(data[\"video\"])))\n",
    "]\n",
    "df_raw = pl.concat(lazy_dfs).collect()\n",
    "\n",
    "frames = df_raw[\"frame\"].unique().sort().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edabebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroids(points: np.ndarray, labels: np.ndarray) -> dict:\n",
    "    centroids = {}\n",
    "    for cluster_id in np.unique(labels):\n",
    "        if cluster_id == -1:\n",
    "            continue\n",
    "        cluster_points = points[labels == cluster_id]\n",
    "        min_x, min_y = cluster_points[:, 0].min(), cluster_points[:, 1].min()\n",
    "        max_x, max_y = cluster_points[:, 0].max(), cluster_points[:, 1].max()\n",
    "        cx, cy = (min_x + max_x) / 2, (min_y + max_y) / 2\n",
    "        centroids[cluster_id] = np.array([cx, cy])\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def match_clusters(\n",
    "    prev_centroids: dict, new_centroids: dict, threshold: float = 1.0\n",
    ") -> dict:\n",
    "    matches = {}\n",
    "    if not prev_centroids or not new_centroids:\n",
    "        return matches\n",
    "\n",
    "    prev_ids = list(prev_centroids.keys())\n",
    "    new_ids = list(new_centroids.keys())\n",
    "    prev_points = np.array([prev_centroids[i] for i in prev_ids])\n",
    "    new_points = np.array([new_centroids[i] for i in new_ids])\n",
    "\n",
    "    dist_matrix = cdist(new_points, prev_points)\n",
    "    for i, new_id in enumerate(new_ids):\n",
    "        min_idx = np.argmin(dist_matrix[i])\n",
    "        if dist_matrix[i, min_idx] <= threshold:\n",
    "            matches[new_id] = prev_ids[min_idx]\n",
    "        else:\n",
    "            matches[new_id] = None\n",
    "    return matches\n",
    "\n",
    "\n",
    "def compute_velocities(\n",
    "    prev_centroids: dict, new_centroids: dict, matches: dict, dt: float = 1.0\n",
    ") -> dict:\n",
    "    velocities = {}\n",
    "    for new_id, prev_id in matches.items():\n",
    "        if prev_id is None:\n",
    "            continue\n",
    "        prev_pos = prev_centroids[prev_id]\n",
    "        new_pos = new_centroids[new_id]\n",
    "        vx, vy = (new_pos - prev_pos) / dt\n",
    "        velocities[new_id] = np.array([vx, vy])\n",
    "    return velocities\n",
    "\n",
    "\n",
    "def predict_positions(\n",
    "    current_centroids: dict, velocities: dict, dt: float = 1.0\n",
    ") -> dict:\n",
    "    preds = {}\n",
    "    for cid, pos in current_centroids.items():\n",
    "        if cid in velocities:\n",
    "            preds[cid] = pos + velocities[cid] * dt\n",
    "        else:\n",
    "            preds[cid] = pos\n",
    "    return preds\n",
    "\n",
    "\n",
    "def update_tracking_state(\n",
    "    state_df: pl.DataFrame,\n",
    "    frame_id: int,\n",
    "    centroids: dict,\n",
    "    velocities: dict,\n",
    "    preds: dict,\n",
    "):\n",
    "    rows = []\n",
    "    for cid in centroids:\n",
    "        cx, cy = centroids[cid]\n",
    "        vx, vy = velocities.get(cid, (np.nan, np.nan))\n",
    "        px, py = preds.get(cid, (np.nan, np.nan))\n",
    "        rows.append((frame_id, cid, cx, cy, vx, vy, px, py))\n",
    "    new_df = pl.DataFrame(\n",
    "        rows,\n",
    "        schema=[\"frame\", \"cluster\", \"cx\", \"cy\", \"vx\", \"vy\", \"px\", \"py\"],\n",
    "        orient=\"row\",\n",
    "    )\n",
    "\n",
    "    return pl.concat([state_df, new_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_dfs = [\n",
    "    pl.scan_csv(os.path.join(data[\"video\"], file)).with_columns(pl.lit(i).alias(\"frame\"))\n",
    "    for i, file in enumerate(sorted(os.listdir(data[\"video\"])))\n",
    "]\n",
    "df_raw = pl.concat(lazy_dfs).collect()\n",
    "frames = df_raw[\"frame\"].unique().sort().to_list()\n",
    "\n",
    "dbscan = DBSCAN(eps=2, min_samples=20)\n",
    "processed_dfs = []\n",
    "prev_centroids, prev_preds = {}, {}\n",
    "next_track_id = 0\n",
    "prev_id_to_track_id = {}\n",
    "\n",
    "for frame_id in tqdm(frames, desc=\"Tracking vehicles\"):\n",
    "    frame_df = df_raw.filter(pl.col(\"frame\") == frame_id)\n",
    "    points = frame_df.select([\"x\", \"y\", \"z\"]).to_numpy()\n",
    "\n",
    "    if len(points) == 0:\n",
    "        continue\n",
    "\n",
    "    labels = dbscan.fit_predict(points)\n",
    "    centroids = compute_centroids(points, labels)\n",
    "    \n",
    "    matches = match_clusters(prev_preds, centroids, threshold=2.5)\n",
    "    current_id_to_track_id = {}\n",
    "    for new_id in centroids.keys():\n",
    "        prev_id = matches.get(new_id)\n",
    "        if prev_id is not None and prev_id in prev_id_to_track_id:\n",
    "            track_id = prev_id_to_track_id[prev_id]\n",
    "            current_id_to_track_id[new_id] = track_id\n",
    "        else:\n",
    "            current_id_to_track_id[new_id] = next_track_id\n",
    "            next_track_id += 1\n",
    "    \n",
    "    track_ids = pl.Series(\"track_id\", labels).replace(current_id_to_track_id).fill_null(-1)\n",
    "    processed_dfs.append(frame_df.with_columns(\n",
    "        pl.Series(\"cluster\", labels),\n",
    "        track_ids\n",
    "    ))\n",
    "\n",
    "    velocities = compute_velocities(prev_centroids, centroids, matches)\n",
    "    preds = predict_positions(centroids, velocities)\n",
    "    \n",
    "    prev_centroids = centroids\n",
    "    prev_preds = preds\n",
    "    prev_id_to_track_id = current_id_to_track_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered = pl.concat(processed_dfs)\n",
    "all_values = pl.concat([df_clustered[\"x\"], df_clustered[\"y\"], df_clustered[\"z\"]])\n",
    "min_global, max_global = all_values.min(), all_values.max()\n",
    "\n",
    "colors = px.colors.qualitative.Plotly\n",
    "animation_frames = []\n",
    "for f in tqdm(frames, desc=\"Adding bounding boxes to the frames\"):\n",
    "    frame_traces = []\n",
    "    current_frame_data = df_clustered.filter(pl.col(\"frame\") == f)\n",
    "\n",
    "    noise_points = current_frame_data.filter(pl.col(\"track_id\") == -1)\n",
    "    if not noise_points.is_empty():\n",
    "        frame_traces.append(go.Scatter3d(\n",
    "            x=noise_points[\"x\"], y=noise_points[\"y\"], z=noise_points[\"z\"],\n",
    "            mode='markers', marker=dict(size=1.5, color='grey', opacity=0.5),\n",
    "            name='Noise'\n",
    "        ))\n",
    "\n",
    "    tracked_ids = current_frame_data.filter(pl.col(\"track_id\") >= 0)[\"track_id\"].unique().sort().to_list()\n",
    "\n",
    "    for track_id in tracked_ids:\n",
    "        cluster_points = current_frame_data.filter(pl.col(\"track_id\") == track_id)\n",
    "        color = colors[track_id % len(colors)]\n",
    "\n",
    "        frame_traces.append(go.Scatter3d(\n",
    "            x=cluster_points[\"x\"], y=cluster_points[\"y\"], z=cluster_points[\"z\"],\n",
    "            mode='markers', marker=dict(size=2, color=color),\n",
    "            name=f'Track ID {track_id}'\n",
    "        ))\n",
    "\n",
    "        min_vals = cluster_points.select([\"x\", \"y\", \"z\"]).min().row(0)\n",
    "        max_vals = cluster_points.select([\"x\", \"y\", \"z\"]).max().row(0)\n",
    "        x_lines, y_lines, z_lines = create_bounding_box_lines(\n",
    "            min_vals[0], max_vals[0], min_vals[1], max_vals[1], min_vals[2], max_vals[2]\n",
    "        )\n",
    "        frame_traces.append(go.Scatter3d(\n",
    "            x=x_lines, y=y_lines, z=z_lines,\n",
    "            mode='lines', line=dict(color=color, width=2.5),\n",
    "            name=f'Box {track_id}'\n",
    "        ))\n",
    "\n",
    "    animation_frames.append(go.Frame(data=frame_traces, name=str(f)))\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=animation_frames[0].data if animation_frames else [],\n",
    "    layout=go.Layout(\n",
    "        width=900, height=700,\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=\"X\", range=[min_global, max_global]),\n",
    "            yaxis=dict(title=\"Y\", range=[min_global, max_global]),\n",
    "            zaxis=dict(title=\"Z\", range=[min_global, max_global]),\n",
    "            aspectmode=\"cube\",\n",
    "        ),\n",
    "        legend=dict(itemsizing='constant', font=dict(size=10)),\n",
    "    ),\n",
    "    frames=animation_frames,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Lidar Point Cloud with Persistent Cluster Tracking\",\n",
    "        x=0.5, y=0.95, xanchor=\"center\", yanchor=\"top\",\n",
    "        font=dict(size=24)\n",
    "    ),\n",
    "    font=dict(family=\"Arial, monospace\", size=12, color=\"Black\"),\n",
    "    sliders=[dict(\n",
    "        steps=[\n",
    "            dict(\n",
    "                args=[[str(f)], dict(frame={\"duration\": 200, \"redraw\": True}, mode=\"immediate\")],\n",
    "                label=str(f),\n",
    "                method=\"animate\",\n",
    "            ) for f in frames\n",
    "        ],\n",
    "        transition={\"duration\": 0},\n",
    "        x=0.1, y=0, len=0.9,\n",
    "    )],\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
